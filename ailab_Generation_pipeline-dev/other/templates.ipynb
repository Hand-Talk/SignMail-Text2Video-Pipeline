{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcb32a2",
   "metadata": {},
   "source": [
    "### We aims at normalize the extracted keypoints from different videos. That is, in different signing videos, the singer may have different distances to the camera, different H/W rate, different height, skeleton feature, etc. We hope to normalize and eliminate all these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d09e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import logging\n",
    "import numpy as np\n",
    "import gc\n",
    "import traceback\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, Manager\n",
    "from pathlib import Path\n",
    "\n",
    "# Change to the model directory for DWPose\n",
    "sys.path.append('./ailab_DWPose_not_git/ControlNet-v1-1-nightly/')\n",
    "from annotator.dwpose import DWposeDetector_canlin_no_output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c15e769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "parsing_resolution = 1024 #we always use 1024 as input image resolution for parsing\n",
    "\n",
    "mp_pose = mp.solutions.pose #pose model\n",
    "mp_face_mesh = mp.solutions.face_mesh # FaceMesh model\n",
    "mp_hands = mp.solutions.hands #hands model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "mp_holistic = mp.solutions.holistic  # Holistic model: used for hand distinguish/trim, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "778a5b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect the landmarks from the image\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #color conversion\n",
    "    image.flags.writeable = False                  #Image is no longer writeable\n",
    "    results = model.process(image)                 #Make prediction\n",
    "    image.flags.writeable = True                   #Image is writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # color conversion\n",
    "    return image, results\n",
    "\n",
    "\n",
    "#formly define the landmark (keypoint) extraction function\n",
    "def extract_keypoints_holistic(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return(pose, face, lh, rh)\n",
    "\n",
    "\n",
    "'''\n",
    "When there's an unexpected handedness value for a single detected hand, \n",
    "we assume it to be the right hand and extract its keypoints.\n",
    "\n",
    "If two hands are detected and either one or both have unexpected handedness values, \n",
    "we extract keypoints for both hands, assigning the first detected hand as right and the \n",
    "second as left.\n",
    "\n",
    "If the handedness value is all expected. We will append the keypoints accordingly.\n",
    "'''\n",
    "\n",
    "def extract_keypoints(pose_results, face_mesh_results, hand_results):\n",
    "    # Extracting Pose Landmarks\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in pose_results.pose_landmarks.landmark]).flatten() if pose_results.pose_landmarks else np.zeros(33 * 3)\n",
    "    \n",
    "    # Extracting Face Landmarks\n",
    "    face = np.array([[res.x, res.y, res.z] for res in face_mesh_results.multi_face_landmarks[0].landmark]).flatten() if face_mesh_results.multi_face_landmarks else np.zeros(478 * 3)\n",
    "    \n",
    "    # Initialize empty hand keypoints\n",
    "    right_hand = np.zeros(21 * 3)\n",
    "    left_hand = np.zeros(21 * 3)\n",
    "\n",
    "    # Check number of hands detected\n",
    "    num_hands_detected = len(hand_results.multi_hand_landmarks) if hand_results.multi_hand_landmarks else 0\n",
    "\n",
    "    valid_handedness_values = ['Right', 'Left']\n",
    "\n",
    "    if num_hands_detected == 1:\n",
    "        # Only one hand is detected, rely on handedness\n",
    "        handedness = hand_results.multi_handedness[0].classification[0].label\n",
    "\n",
    "        # Check for valid handedness value\n",
    "        if handedness not in valid_handedness_values:\n",
    "            # Handle unexpected handedness value here (e.g., log a warning, skip the frame, etc.)\n",
    "            print(f\"Warning: Unexpected handedness value '{handedness}'\")\n",
    "            right_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[0].landmark]).flatten()\n",
    "            return pose, face, right_hand, left_hand\n",
    "        \n",
    "        if handedness == 'Right':\n",
    "            right_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[0].landmark]).flatten()\n",
    "        else:\n",
    "            left_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[0].landmark]).flatten()\n",
    "    \n",
    "    elif num_hands_detected == 2:\n",
    "        # Two hands are detected, first check handedness\n",
    "        handedness_0 = hand_results.multi_handedness[0].classification[0].label\n",
    "        handedness_1 = hand_results.multi_handedness[1].classification[0].label\n",
    "\n",
    "        # Check for valid handedness values\n",
    "        if handedness_0 not in valid_handedness_values or handedness_1 not in valid_handedness_values:\n",
    "            print(f\"Warning: Unexpected handedness values '{handedness_0}' and '{handedness_1}'\")\n",
    "            right_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[0].landmark]).flatten()\n",
    "            left_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[1].landmark]).flatten()\n",
    "            return pose, face, right_hand, left_hand\n",
    "        \n",
    "        # If both hands have different handedness\n",
    "        if handedness_0 != handedness_1:\n",
    "            if handedness_0 == 'Right':\n",
    "                right_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[0].landmark]).flatten()\n",
    "                left_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[1].landmark]).flatten()\n",
    "            else:\n",
    "                right_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[1].landmark]).flatten()\n",
    "                left_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[0].landmark]).flatten()\n",
    "        \n",
    "        # If both hands are detected as the same handedness\n",
    "        else:\n",
    "            # Ignore handedness and assign the first as right hand and the second as left hand\n",
    "            right_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[0].landmark]).flatten()\n",
    "            left_hand = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_results.multi_hand_landmarks[1].landmark]).flatten()\n",
    "    \n",
    "    '''\n",
    "    The handedness assume the image is mirrored, which is not true for Signing Savvy.\n",
    "    As a result, we will just switch the left and right hand!\n",
    "    '''\n",
    "    temp = right_hand\n",
    "    right_hand = left_hand\n",
    "    left_hand = temp\n",
    "    del(temp)\n",
    "    \n",
    "    return pose, face, right_hand, left_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "418d1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_array(arr):\n",
    "    if len(arr) % 3 != 0:\n",
    "        raise ValueError(\"The length of the array must be a multiple of 3.\")\n",
    "    return arr.reshape(-1, 3)\n",
    "\n",
    "\n",
    "def zero_rate(arr):\n",
    "    \"\"\"\n",
    "    Compute the rate of zeros in a given 1D numpy array.\n",
    "\n",
    "    Parameters:\n",
    "    - arr (np.array): 1D numpy array\n",
    "\n",
    "    Returns:\n",
    "    - float: rate of zeros in the array\n",
    "    \"\"\"\n",
    "    num_zeros = np.sum(arr == 0)\n",
    "    rate = num_zeros / len(arr)\n",
    "    return rate\n",
    "\n",
    "\n",
    "#two supportive functions:\n",
    "def euclidean_distance(point1, point2):\n",
    "    return ((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2) ** 0.5\n",
    "\n",
    "\n",
    "def dimensionwise_distance(hand1, hand2):\n",
    "    \"\"\"Computes the dimension-wise distance between two hands, ignoring z-values.\"\"\"\n",
    "    distances = [abs(a - b) for i, (a, b) in enumerate(zip(hand1, hand2)) if i % 3 != 2]\n",
    "    return sum(distances)\n",
    "\n",
    "\n",
    "'''We apply the strict L-2 distance here'''\n",
    "def dimensionwise_distance_single_max(hand1, hand2):\n",
    "    if len(hand1) % 3 != 0 or len(hand2) % 3 != 0:\n",
    "        raise ValueError(\"Hand keypoints should be a multiple of 3\")\n",
    "    \n",
    "    # Compute the L-2 distance for each pair of (xi, yi) points, \n",
    "    # considering zero distances if either of the keypoints is zero.\n",
    "    distances = [\n",
    "        0 if (hand1[i] == 0 and hand1[i+1] == 0) or (hand2[i] == 0 and hand2[i+1] == 0) \n",
    "        else ((hand1[i] - hand2[i])**2 + (hand1[i+1] - hand2[i+1])**2)**0.5 \n",
    "        for i in range(0, len(hand1), 3)\n",
    "    ]\n",
    "    return max(distances)\n",
    "\n",
    "\n",
    "'''we calculate the average-distance based on L2'''\n",
    "def dimensionwise_distance_single_avg(hand1, hand2):\n",
    "    \n",
    "    if len(hand1) % 3 != 0 or len(hand2) % 3 != 0:\n",
    "        raise ValueError(\"Hand keypoints should be a multiple of 3\")\n",
    "        \n",
    "    # If either hand is mostly zeros, return zero\n",
    "    if zero_rate(hand1) > 0.5 or zero_rate(hand2) > 0.5:\n",
    "        return 0.\n",
    "        \n",
    "    # Compute the L-2 distance for each pair of (xi, yi) points.\n",
    "    distances = [((hand1[i] - hand2[i])**2 + (hand1[i+1] - hand2[i+1])**2)**0.5 for i in range(0, len(hand1), 3)]\n",
    "    \n",
    "    # Calculate the average distance if there are any distances calculated\n",
    "    if distances:\n",
    "        return sum(distances) / len(distances)\n",
    "    else:\n",
    "        return 0.  # Return 0 if no distances to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3dde141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We define overlap hand like this: The left and right hand (both hands) are not zeros, and\n",
    "their elementwise distence is less than the threshold. Also, we in addition require that\n",
    "overlapped hands is close to one wrist, while the other wrist is missing or outside the image.\n",
    "\n",
    "In this case, we will delete one hand (change to zero): we will assume the left/right hand\n",
    "assignment is correct, which is basically proved to be true on character sign videos.\n",
    "Then, we will delete the hand from the far away pose wrist.\n",
    "\n",
    "Note that the distance_threshold here is different from that in correct_handedness_temporal.\n",
    "'''\n",
    "\n",
    "#function to detect & remove one hand if both hands are overlapping\n",
    "def handle_overlap_hand_new(pose_landmark, left_hand, right_hand):\n",
    "    \n",
    "    #pose_landmark = data_dict['pose']\n",
    "    #left_hand = data_dict['left_hand']\n",
    "    #right_hand = data_dict['right_hand']\n",
    "    \n",
    "    #only make sense to continue if both and are not zeros\n",
    "    if any(value != 0 for value in left_hand) and any(value != 0 for value in right_hand):\n",
    "    \n",
    "        hand_d = dimensionwise_distance(left_hand, right_hand)\n",
    "\n",
    "        #left wrist to right hand wrist, similar naming strategy below\n",
    "        l_d_r = euclidean_distance([pose_landmark[15 * 3], pose_landmark[15 * 3 + 1]], \n",
    "                                   [right_hand[0], right_hand[1]])\n",
    "        l_d_l = euclidean_distance([pose_landmark[15 * 3], pose_landmark[15 * 3 + 1]], \n",
    "                                   [left_hand[0], left_hand[1]])\n",
    "        r_d_r = euclidean_distance([pose_landmark[16 * 3], pose_landmark[16 * 3 + 1]], \n",
    "                                   [right_hand[0], right_hand[1]])\n",
    "        r_d_l = euclidean_distance([pose_landmark[16 * 3], pose_landmark[16 * 3 + 1]], \n",
    "                                   [left_hand[0], left_hand[1]])\n",
    "\n",
    "        #0.4 is the threshold for dimensionwise distance, we have testify this value, should be fine\n",
    "        # !!!!! 0.4 is different from the SL Generation code, where we use 0.6. We are more cautious here.\n",
    "        #0.08 is the lower bound wrist distance, 0.3 is the upper bound\n",
    "        #this says that: if hands are close and (hands are close to one wrist, away from the other wrist, or the other wrist is outside the image)\n",
    "        if (hand_d <= 0.4) and ((r_d_r <= 0.08 and (l_d_r >= 0.3 or pose_landmark[15 * 3] >= 0.93 or pose_landmark[15 * 3 + 1] >= 0.93)) or (\n",
    "                                 l_d_r <= 0.08 and (r_d_r >= 0.3 or pose_landmark[16 * 3] >= 0.93 or pose_landmark[16 * 3 + 1] >= 0.93)) or (\n",
    "                                 r_d_l <= 0.08 and (l_d_l >= 0.3 or pose_landmark[15 * 3] >= 0.93 or pose_landmark[15 * 3 + 1] >= 0.93)) or (\n",
    "                                 l_d_l <= 0.08 and (r_d_l >= 0.3 or pose_landmark[16 * 3] >= 0.93 or pose_landmark[16 * 3 + 1] >= 0.93))):\n",
    "\n",
    "            #right wrist close: so left wrist should be far away or outside, so we remove left hand\n",
    "            if r_d_r <= 0.08 or r_d_l <= 0.08:\n",
    "                left_hand = np.zeros(21 * 3)\n",
    "\n",
    "            #left wrist close: so right wrist should be far away or outside, so we remove right hand\n",
    "            if l_d_r <= 0.08 or l_d_l <= 0.08:\n",
    "                right_hand = np.zeros(21 * 3)\n",
    "                \n",
    "    return(left_hand, right_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe5bb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_invalid_dimensions(array_2):\n",
    "    \"\"\"\n",
    "    Count the number of invalid dimensions in array_2 (DWPose).\n",
    "    An invalid dimension is defined as having either x or y coordinates to be -1.\n",
    "    \n",
    "    !!!!! In the same function previously (in extract_kp_from_Kylie_data), we define\n",
    "    invalid dimension as both x and y equals -1. This is not good:\n",
    "    In SL_generation code, we force x and y to be -1 if either of them is -1.\n",
    "    But without this procedure, ususally we cannot assume both x and y to be -1.\n",
    "    Hence, we changed to either x or y coordinates to be -1.\n",
    "    That says, the kp_extract_main_0 and 1.py has defult in extract_kp_from_Kylie_data!\n",
    "    But luckly we do not use DWPose at all so doesn't matter.....\n",
    "    \n",
    "    Finally, instead of checking whether the value exactly match -1, we check < -0.9 instead\n",
    "\n",
    "    Parameters:\n",
    "    - array_2 (np.ndarray): 2D array of keypoints [x1, y1], [x2, y2], ..., [xn, yn]\n",
    "\n",
    "    Returns:\n",
    "    - int: Number of invalid dimensions\n",
    "    \"\"\"\n",
    "    num_invalid = 0\n",
    "    for dim in array_2:\n",
    "        if dim[0] < -0.9 or dim[1] < -0.9:\n",
    "            num_invalid += 1\n",
    "            \n",
    "        #print(dim)\n",
    "    return num_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68422fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_DW_hand_dist(array_1, array_2):\n",
    "    \"\"\"\n",
    "    Calculate the average and maximum Euclidean distances between corresponding keypoints \n",
    "    in array_1 and array_2 based on x and y coordinates, excluding keypoints in array_2\n",
    "    \n",
    "    !!!!! Same story, we changed checking [-1, -1] to check either x or y < 0.9.\n",
    "    This is different from extract_kp_from_Kylie_data.\n",
    "\n",
    "    Parameters:\n",
    "    - array_1 (np.ndarray): 1D array of keypoints including z coordinates [x1, y1, z1, ..., xn, yn, zn]\n",
    "    - array_2 (np.ndarray): 2D array of keypoints [[x1, y1], [x2, y2], ..., [xn, yn]]\n",
    "\n",
    "    Returns:\n",
    "    - float: average distance between valid keypoints\n",
    "    - float: maximum distance between valid keypoints\n",
    "    \"\"\"\n",
    "    # Reshape array_1 to extract x and y coordinates, ignoring z coordinates\n",
    "    xy_array_1 = array_1.reshape(-1, 3)[:, :2]\n",
    "    \n",
    "    # Ensure array_2 is a numpy array (in case it isn't)\n",
    "    array_2 = np.array(array_2)\n",
    "    \n",
    "    # Create a mask manually to filter out invalid keypoints from array_2\n",
    "    valid_mask = []\n",
    "    for point in array_2:\n",
    "        if point[0] < -0.9 or point[1] < -0.9:\n",
    "            valid_mask.append(False)\n",
    "        else:\n",
    "            valid_mask.append(True)\n",
    "    \n",
    "    # Convert list to numpy array for indexing\n",
    "    valid_mask = np.array(valid_mask)\n",
    "    \n",
    "    # Apply mask to both arrays\n",
    "    valid_xy_array_1 = xy_array_1[valid_mask]\n",
    "    valid_array_2 = array_2[valid_mask]\n",
    "    \n",
    "    # Calculate Euclidean distances between valid keypoints\n",
    "    distances = np.linalg.norm(valid_xy_array_1 - valid_array_2, axis=1)\n",
    "    \n",
    "    # Calculate average and maximum distance\n",
    "    if distances.size == 0:  # Check if there are no valid points after masking\n",
    "        return float(10), float(10)  # Return NaN if no valid distances to calculate\n",
    "    else:\n",
    "        average_distance = np.mean(distances)\n",
    "        maximum_distance = np.max(distances)\n",
    "    \n",
    "    return(average_distance, maximum_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70f9610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given the mediapipe hand, we want to decide whether it is more 'left' or more 'right':\n",
    "    We will calculate the distance between this hand and each DWpose hand, 1/distance will be the score\n",
    "    We will calculate the distance between this hand wrist and each DWpose wrist, 1/distance is the score\n",
    "    We add the score to decide its left score or right score, indicating how 'left' the given hand is, how right the given hand is.\n",
    "'''\n",
    "# this is the function to actually choose the most appropriate hand\n",
    "def left_or_right_for_given_hand(given_hand, l_h_DW, r_h_DW, l_w_DW, r_w_DW):\n",
    "    \n",
    "    #the score on whether the given mediapipe hand is 'how left' or 'how right'\n",
    "    l_score, r_score = 0., 0.\n",
    "    \n",
    "    #DWPose hand vote, must be not too much [-1,-1], in which case we trust it the most\n",
    "    if count_invalid_dimensions(l_h_DW) <= 3: #left \n",
    "        ave_l, max_l = mp_DW_hand_dist(given_hand, l_h_DW)\n",
    "        l_score += 1/(ave_l + 0.00000001)\n",
    "    \n",
    "    if count_invalid_dimensions(r_h_DW) <= 3: #right\n",
    "        ave_r, max_r = mp_DW_hand_dist(given_hand, r_h_DW)\n",
    "        r_score += 1/(ave_r + 0.00000001)\n",
    "\n",
    "\n",
    "    #left pose wrist vote, must be non-zero and not -1 (valid) pose\n",
    "    if l_w_DW[0] >= -0.9 and l_w_DW[1] >= -0.9 and l_w_DW[0] != 0 and l_w_DW[1] != 0:\n",
    "        x1 = l_w_DW[0]\n",
    "        y1 = l_w_DW[1]\n",
    "        \n",
    "        x2 = given_hand[0]\n",
    "        y2 = given_hand[1]\n",
    "        \n",
    "        distance = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "        l_score += 0.4/(distance + 0.00000001) #0.4 is the weight we add to wrist decision\n",
    "        \n",
    "    #right pose wrist vote, must be non-zero (valid) pose\n",
    "    if r_w_DW[0] >= -0.9 and r_w_DW[1] >= -0.9 and r_w_DW[0] != 0 and r_w_DW[1] != 0:\n",
    "        x1 = r_w_DW[0]\n",
    "        y1 = r_w_DW[1]\n",
    "        \n",
    "        x2 = given_hand[0]\n",
    "        y2 = given_hand[1]\n",
    "        \n",
    "        distance = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "        r_score += 0.4/(distance + 0.00000001)\n",
    "\n",
    "    return(l_score, r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0edf91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to finally decide left/right hand\n",
    "def decide_l_r_hand(lh, rh, lh_DW, rh_DW, lw, rw):\n",
    "    \n",
    "    #calculate with DWPose only if the mediapipe hand is not zero\n",
    "    if zero_rate(lh) < 0.2:\n",
    "        #l_l is how 'left hand' the left hand looks like\n",
    "        #r_l is how 'right hand' the left hand looks liks \n",
    "        l_l, r_l = left_or_right_for_given_hand(lh, lh_DW, rh_DW, lw, rw)\n",
    "    else:\n",
    "        l_l, r_l = 0., 0.\n",
    "    \n",
    "    #calculate with DWPose only if the mediapipe hand is not zero\n",
    "    if zero_rate(rh) < 0.2:\n",
    "        #similarly, l_r is how 'left hand' right hand looks like\n",
    "        #r_r is how 'right hand' the right hand looks like\n",
    "        l_r, r_r = left_or_right_for_given_hand(rh, lh_DW, rh_DW, lw, rw)\n",
    "    else:\n",
    "        l_r, r_r = 0., 0.\n",
    "    \n",
    "    List = [['l_l', l_l], ['r_l', r_l], ['l_r', l_r], ['r_r', r_r]]\n",
    "        \n",
    "    List = sorted(List, key=lambda x: x[1], reverse=True)\n",
    "    top_sub_list = List[0] #top top_sub_list is the highest score hand\n",
    "    top_str = top_sub_list[0]\n",
    "    \n",
    "    hand_should_be = top_str.split('_')[0]\n",
    "    actual_hand = top_str.split('_')[1]\n",
    "    \n",
    "    #return: decided left hand, decided right hand\n",
    "    #if reverted, we return 'Reverted', otherwise return 'Not_reverted'\n",
    "    if hand_should_be == 'l' and actual_hand == 'l':\n",
    "        return(lh, rh, 'Not_reverted')\n",
    "    if hand_should_be == 'l' and actual_hand == 'r':\n",
    "        return(rh, lh, 'Reverted')\n",
    "    if hand_should_be == 'r' and actual_hand == 'l':\n",
    "        return(rh, lh, 'Reverted')\n",
    "    if hand_should_be == 'r' and actual_hand == 'r':\n",
    "        return(lh, rh, 'Not_reverted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "259b3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_scattered_keypoints(keypoints, bd_1=0.96, bd_2=0.86):\n",
    "    \"\"\"\n",
    "    Fix scattered keypoints in a hand keypoint array.\n",
    "\n",
    "    :param keypoints: A (21, 2) numpy array of hand keypoints.\n",
    "    :return: A (21, 2) numpy array with scattered points replaced by [-1, -1].\n",
    "    \n",
    "    We detect scatterred points like this:\n",
    "    if there exists keypoints with y >= bd_1;\n",
    "    if there exists keypoints with y <= bd_2;\n",
    "    but there is not keypoint with y in between;\n",
    "    \n",
    "    Then, we regard all the keypoints with y <= bd_2 scattered points, we change to [-1 -1]\n",
    "    \"\"\"\n",
    "    # Set the other value to -1 if one is -1\n",
    "    for i in range(len(keypoints)):\n",
    "        if keypoints[i][0] == -1 or keypoints[i][1] == -1:\n",
    "            keypoints[i] = np.asarray([-1, -1])\n",
    "\n",
    "    # Check the specified conditions for scattered points\n",
    "    has_low_keypoints = any(point[1] >= bd_1 for point in keypoints if point[1] != -1)\n",
    "    has_high_keypoints = any(point[1] <= bd_2 for point in keypoints if point[1] != -1)\n",
    "    has_no_mid_keypoints = not any(bd_2 < point[1] < bd_1 for point in keypoints if point[1] != -1)\n",
    "\n",
    "    # If conditions are met, fix scattered points\n",
    "    if has_low_keypoints and has_high_keypoints and has_no_mid_keypoints:\n",
    "        for i in range(len(keypoints)):\n",
    "            if keypoints[i][1] != -1 and keypoints[i][1] <= bd_2:\n",
    "                keypoints[i] = np.asarray([-1, -1])\n",
    "\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "636715ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_key_vector(file_name, model):\n",
    "    \n",
    "    #Dict = defaultdict(dict)\n",
    "    vec_array = list()\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic, \\\n",
    "         mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose_func, \\\n",
    "         mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh_func, \\\n",
    "         mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands_func:\n",
    "\n",
    "        vidcap = cv2.VideoCapture(file_name)\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        number_of_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Get the video's original width and height\n",
    "        frame_height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        frame_width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "        success, image = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "\n",
    "            #####Mediapipe detections############\n",
    "            _, results = mediapipe_detection(image, holistic)\n",
    "            _, pose_results = mediapipe_detection(image, pose_func)\n",
    "            _, face_mesh_results = mediapipe_detection(image, face_mesh_func)\n",
    "            _, hand_results = mediapipe_detection(image, hands_func)\n",
    "            \n",
    "            # Transfer keypoint results into arrays\n",
    "            pose, face, rh, lh = extract_keypoints(pose_results, face_mesh_results, hand_results)\n",
    "            \n",
    "            #obtain the keypoint array from the holistic model\n",
    "            pose_ho, face_ho, lh_ho, rh_ho = extract_keypoints_holistic(results)\n",
    "            \n",
    "            #deal with overlapped hands first\n",
    "            lh, rh = handle_overlap_hand_new(pose, lh, rh)\n",
    "            lh_ho, rh_ho = handle_overlap_hand_new(pose, lh_ho, rh_ho)\n",
    "            \n",
    "            kp_vectors = model(image)\n",
    "\n",
    "            fixed_l = fix_scattered_keypoints(kp_vectors['hands'][0])\n",
    "            fixed_r = fix_scattered_keypoints(kp_vectors['hands'][1])\n",
    "            kp_vectors['hands'][0] = fixed_l\n",
    "            kp_vectors['hands'][1] = fixed_r\n",
    "            kp_vectors['bodies']['candidate'] = deepcopy(kp_vectors['bodies']['candidate'][:18, :])\n",
    "            \n",
    "            ####Left/Right hand correction of mediapipe#######\n",
    "            lh, rh, revert = decide_l_r_hand(lh, rh, kp_vectors['hands'][0], \n",
    "                                                     kp_vectors['hands'][1], \n",
    "                                                     pose[45:48], pose[48:51])\n",
    "            \n",
    "            lh_ho, rh_ho, revert_ho = decide_l_r_hand(lh_ho, rh_ho, kp_vectors['hands'][0], \n",
    "                                                                    kp_vectors['hands'][1], \n",
    "                                                                    pose[45:48], pose[48:51])\n",
    "\n",
    "            \n",
    "            ####add mediapipe stuff###############\n",
    "            kp_vectors['pose_mp'] = pose\n",
    "            kp_vectors['face_mp'] = face\n",
    "                        \n",
    "            kp_vectors['pose_holistic_mp'] = pose_ho\n",
    "            kp_vectors['face_holistic_mp'] = face_ho\n",
    "            \n",
    "            if zero_rate(lh) < 0.2:\n",
    "                kp_vectors['left_hand_mp'] = lh\n",
    "            else:\n",
    "                kp_vectors['left_hand_mp'] = lh_ho\n",
    "            \n",
    "            if zero_rate(rh) < 0.2:\n",
    "                kp_vectors['right_hand_mp'] = rh\n",
    "            else:\n",
    "                kp_vectors['right_hand_mp'] = rh_ho\n",
    "            \n",
    "            kp_vectors['left_hand_holistic_mp'] = lh_ho\n",
    "            kp_vectors['right_hand_holistic_mp'] = rh_ho\n",
    "\n",
    "            kp_vectors['hand_revert'] = revert\n",
    "            kp_vectors['holistic_hand_revert'] = revert_ho\n",
    "\n",
    "            vec_array.append(kp_vectors)\n",
    "\n",
    "            success, image = vidcap.read()\n",
    "            count += 1\n",
    "\n",
    "\n",
    "        vidcap.release()\n",
    "        \n",
    "    return vec_array, fps, number_of_frames, frame_height, frame_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5af00c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D: [0.2 0.3 0.1 0.4 0.5 0.2]\n",
      "Resized 1D: [0.3 0.6 0.1 0.6 1.  0.2]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "Original 2D: [[0.2 0.3]\n",
      " [0.4 0.5]]\n",
      "Resized 2D: [[0.3 0.6]\n",
      " [0.6 1. ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# !!!!!!!!!!!!! not used in fact\n",
    "def resize_keypoints(keypoints, resize_height_rate, resize_width_rate):\n",
    "    \"\"\"\n",
    "    Resize keypoints by given rates, keeping the upper-left point (0,0) as invariant.\n",
    "    \n",
    "    Args:\n",
    "        keypoints: numpy array in either:\n",
    "                    - 1D format (x1,y1,z1, x2,y2,z2, ...)\n",
    "                    - 2D format ((x1,y1), (x2,y2), ...)\n",
    "        resize_height_rate: float, rate to resize in height (y-direction)\n",
    "        resize_width_rate: float, rate to resize in width (x-direction)\n",
    "    \n",
    "    Returns:\n",
    "        numpy array with same format as input but with resized coordinates\n",
    "    \"\"\"\n",
    "    # Convert input to numpy array if it isn't already\n",
    "    keypoints = np.array(keypoints)\n",
    "    \n",
    "    # Detect input format (1D or 2D)\n",
    "    is_1d = len(keypoints.shape) == 1\n",
    "    \n",
    "    if is_1d:\n",
    "        # 1D format with z-values\n",
    "        n_points = len(keypoints) // 3  # Each point has (x,y,z)\n",
    "        # Reshape to (n_points, 3)\n",
    "        points = keypoints.reshape(n_points, 3)\n",
    "        # Scale x and y, keep z unchanged\n",
    "        points[:, 0] *= resize_width_rate   # x coordinates\n",
    "        points[:, 1] *= resize_height_rate  # y coordinates\n",
    "        # Flatten back to 1D\n",
    "        return points.reshape(-1)\n",
    "    else:\n",
    "        # 2D format without z-values\n",
    "        resized = keypoints.copy()\n",
    "        resized[:, 0] *= resize_width_rate    # x coordinates\n",
    "        resized[:, 1] *= resize_height_rate   # y coordinates\n",
    "        return resized\n",
    "\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with 1D format (with z)\n",
    "    kp_1d = np.array([0.2, 0.3, 0.1, 0.4, 0.5, 0.2])  # Two points: (0.2, 0.3, 0.1), (0.4, 0.5, 0.2)\n",
    "    resized_1d = resize_keypoints(kp_1d, resize_height_rate=2.0, resize_width_rate=1.5)\n",
    "    print(\"Original 1D:\", kp_1d)\n",
    "    print(\"Resized 1D:\", resized_1d)\n",
    "    print(type(resized_1d))\n",
    "    \n",
    "    # Test with 2D format\n",
    "    kp_2d = np.array([[0.2, 0.3], [0.4, 0.5]])  # Two points: (0.2, 0.3), (0.4, 0.5)\n",
    "    resized_2d = resize_keypoints(kp_2d, resize_height_rate=2.0, resize_width_rate=1.5)\n",
    "    print(\"\\nOriginal 2D:\", kp_2d)\n",
    "    print(\"Resized 2D:\", resized_2d)\n",
    "    print(type(resized_2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58868705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 1D: [0.2 0.3 0.1 0.4 0.5 0.2]\n",
      "Moved 1D: [0.3 0.1 0.1 0.5 0.3 0.2]\n",
      "\n",
      "Original 2D: [[0.2 0.3]\n",
      " [0.4 0.5]]\n",
      "Moved 2D: [[0.3 0.1]\n",
      " [0.5 0.3]]\n"
     ]
    }
   ],
   "source": [
    "# !!!!!!!!!!!!! not used in fact\n",
    "def move_keypoints(keypoints, x0, y0):\n",
    "    \"\"\"\n",
    "    Move keypoints by adding (x0, y0) to all (x, y) coordinates.\n",
    "    Z coordinates (if present) remain unchanged.\n",
    "    \n",
    "    Args:\n",
    "        keypoints: numpy array in either:\n",
    "                    - 1D format (x1,y1,z1, x2,y2,z2, ...)\n",
    "                    - 2D format ((x1,y1), (x2,y2), ...)\n",
    "        x0: float, displacement in x direction\n",
    "        y0: float, displacement in y direction\n",
    "    \n",
    "    Returns:\n",
    "        numpy array with same format as input but with moved coordinates\n",
    "    \"\"\"\n",
    "    # Convert input to numpy array if it isn't already\n",
    "    keypoints = np.array(keypoints)\n",
    "    \n",
    "    # Detect input format (1D or 2D)\n",
    "    is_1d = len(keypoints.shape) == 1\n",
    "    \n",
    "    if is_1d:\n",
    "        # 1D format with z-values\n",
    "        n_points = len(keypoints) // 3  # Each point has (x,y,z)\n",
    "        # Reshape to (n_points, 3)\n",
    "        points = keypoints.reshape(n_points, 3)\n",
    "        # Move x and y, keep z unchanged\n",
    "        points[:, 0] += x0   # x coordinates\n",
    "        points[:, 1] += y0   # y coordinates\n",
    "        # Flatten back to 1D\n",
    "        return points.reshape(-1)\n",
    "    else:\n",
    "        # 2D format without z-values\n",
    "        moved = keypoints.copy()\n",
    "        moved[:, 0] += x0    # x coordinates\n",
    "        moved[:, 1] += y0    # y coordinates\n",
    "        return moved\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with 1D format (with z)\n",
    "    kp_1d = np.array([0.2, 0.3, 0.1, 0.4, 0.5, 0.2])  # Two points: (0.2, 0.3, 0.1), (0.4, 0.5, 0.2)\n",
    "    moved_1d = move_keypoints(kp_1d, x0=0.1, y0=-0.2)\n",
    "    print(\"Original 1D:\", kp_1d)\n",
    "    print(\"Moved 1D:\", moved_1d)\n",
    "    \n",
    "    # Test with 2D format\n",
    "    kp_2d = np.array([[0.2, 0.3], [0.4, 0.5]])  # Two points: (0.2, 0.3), (0.4, 0.5)\n",
    "    moved_2d = move_keypoints(kp_2d, x0=0.1, y0=-0.2)\n",
    "    print(\"\\nOriginal 2D:\", kp_2d)\n",
    "    print(\"Moved 2D:\", moved_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bb64c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance between [0.34080809, 0.56194119] and [0.66353743, 0.5563285]: 0.323\n"
     ]
    }
   ],
   "source": [
    "def compute_l2_distance(array1, array2):\n",
    "    \"\"\"\n",
    "    Compute L2 (Euclidean) distance between two 1D arrays\n",
    "    \n",
    "    Parameters:\n",
    "    array1, array2: arrays of same length\n",
    "    \n",
    "    Returns:\n",
    "    float: L2 distance between the arrays\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays if they aren't already\n",
    "    a1 = np.array(array1)\n",
    "    a2 = np.array(array2)\n",
    "    \n",
    "    # Compute L2 distance\n",
    "    distance = np.sqrt(np.sum((a1 - a2) ** 2))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "x1, y1 = [0.34080809, 0.56194119]\n",
    "x2, y2 = [0.66353743, 0.5563285]\n",
    "\n",
    "distance = compute_l2_distance([x1, y1], [x2, y2])\n",
    "print(f\"L2 distance between {[x1, y1]} and {[x2, y2]}: {distance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69f109f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed keypoints:\n",
      "\n",
      "bodies:\n",
      "{'candidate': array([[ 0.85,  0.4 ],\n",
      "       [ 1.  ,  0.6 ],\n",
      "       [-1.  , -1.  ]]), 'subset': array([[0., 1., 2.]])}\n",
      "\n",
      "hands:\n",
      "[[[ 1.15  1.4 ]\n",
      "  [ 1.45  1.8 ]]\n",
      "\n",
      " [[ 0.25  0.2 ]\n",
      "  [-1.   -1.  ]]]\n",
      "\n",
      "faces:\n",
      "[[[0.7  0.4 ]\n",
      "  [0.85 0.6 ]]]\n",
      "\n",
      "pose_mp:\n",
      "[0.85 0.4  0.1  1.   0.6  0.2 ]\n",
      "\n",
      "left_hand_mp:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "confidence_score_mp:\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "def process_keypoints(keypoints_dict, resize_height_rate=1.0, resize_width_rate=1.0, move_x=0.0, move_y=0.0):\n",
    "    \"\"\"\n",
    "    Resize and move keypoints in the dictionary while maintaining specific formats and rules.\n",
    "    \n",
    "    Args:\n",
    "        keypoints_dict: Dictionary containing different types of keypoints\n",
    "        resize_height_rate: float, rate to resize in height (y-direction)\n",
    "        resize_width_rate: float, rate to resize in width (x-direction)\n",
    "        move_x: float, displacement in x direction\n",
    "        move_y: float, displacement in y direction\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with processed keypoints\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    # Helper function to process 2D array of shape (..., 2)\n",
    "    def process_2d_points(points):\n",
    "        # Check for invalid points (x or y < -0.9)\n",
    "        invalid_mask = np.any(points < -0.9, axis=-1)\n",
    "        \n",
    "        # Process valid points\n",
    "        processed = points.copy()\n",
    "        processed[..., 0] = points[..., 0] * resize_width_rate + move_x\n",
    "        processed[..., 1] = points[..., 1] * resize_height_rate + move_y\n",
    "        \n",
    "        # Reset invalid points to [-1, -1]\n",
    "        processed[invalid_mask] = [-1, -1]\n",
    "        return processed\n",
    "    \n",
    "    # Helper function to process 1D array with z values\n",
    "    def process_1d_points_with_z(points):\n",
    "        if np.all(points == 0):  # If all zeros, return as is\n",
    "            return points\n",
    "            \n",
    "        n_points = len(points) // 3\n",
    "        reshaped = points.reshape(n_points, 3)\n",
    "        \n",
    "        # Process x and y, keep z unchanged\n",
    "        reshaped[:, 0] = reshaped[:, 0] * resize_width_rate + move_x\n",
    "        reshaped[:, 1] = reshaped[:, 1] * resize_height_rate + move_y\n",
    "        \n",
    "        return reshaped.reshape(-1)\n",
    "    \n",
    "    # Process DWPose body keypoints\n",
    "    if 'bodies' in keypoints_dict:\n",
    "        result_dict['bodies'] = {\n",
    "            'candidate': process_2d_points(keypoints_dict['bodies']['candidate']),\n",
    "            'subset': keypoints_dict['bodies']['subset'].copy()  # Keep subset unchanged\n",
    "        }\n",
    "    \n",
    "    # Process DWPose hands\n",
    "    if 'hands' in keypoints_dict:\n",
    "        result_dict['hands'] = process_2d_points(keypoints_dict['hands'])\n",
    "    \n",
    "    # Process DWPose faces (unstack first dim)\n",
    "    if 'faces' in keypoints_dict:\n",
    "        faces = keypoints_dict['faces']\n",
    "        processed_faces = process_2d_points(faces[0])  # Process the unstacked array\n",
    "        result_dict['faces'] = processed_faces[np.newaxis, ...]  # Stack back\n",
    "    \n",
    "    # Process MediaPipe keypoints (all ending with _mp)\n",
    "    for key in keypoints_dict:\n",
    "        if key.endswith('_mp'):\n",
    "            if key == 'confidence_score_mp':\n",
    "                result_dict[key] = keypoints_dict[key]  # Keep confidence score unchanged\n",
    "            else:\n",
    "                result_dict[key] = process_1d_points_with_z(keypoints_dict[key])\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a small example dictionary\n",
    "    example_dict = {\n",
    "        'bodies': {\n",
    "            'candidate': np.array([[0.5, 0.3], [0.6, 0.4], [-1, -1]]),\n",
    "            'subset': np.array([[0., 1., 2.]])\n",
    "        },\n",
    "        'hands': np.array([[[0.7, 0.8], [0.9, 1.0]], [[0.1, 0.2], [-1, -1]]]),\n",
    "        'faces': np.array([[[0.4, 0.3], [0.5, 0.4]]]),\n",
    "        'pose_mp': np.array([0.5, 0.3, 0.1, 0.6, 0.4, 0.2]),\n",
    "        'left_hand_mp': np.zeros(63),  # Example with all zeros\n",
    "        'confidence_score_mp': 3.0\n",
    "    }\n",
    "    \n",
    "    # Process the keypoints\n",
    "    processed = process_keypoints(\n",
    "        example_dict,\n",
    "        resize_height_rate=2.0,\n",
    "        resize_width_rate=1.5,\n",
    "        move_x=0.1,\n",
    "        move_y=-0.2\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Processed keypoints:\")\n",
    "    for key in processed:\n",
    "        print(f\"\\n{key}:\")\n",
    "        print(processed[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bfb610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to actually implement normalization of keypoints\n",
    "'''\n",
    "std_sholder is the sholder L-2 distance (consider both x and y) of the DWPose.\n",
    "That is, the dist between Dict['body']['candidate'][2] and Dict['body']['candidate'][5]\n",
    "\n",
    "std_neck is the neck-end to nose L-2 distence of the DWPose.\n",
    "That is, the dist between Dict['body']['candidate'][0] and Dict['body']['candidate'][1]\n",
    "\n",
    "std_sholder=0.323, std_neck=0.197 is obtained from\n",
    "../../data/SigningSavvy_Dict/new_2_key_vectors_indpt_h_adjust_DWPose/a/1-#-the-letter-a/2.pickle\n",
    "That is, the first frame of lady Brenda signing letter a in fingerspelling.\n",
    "\n",
    "Similarly, we use this frame of lady Branda to decide the center (neck end, note 1 in DWPose body)\n",
    "x=0.50217276, y=0.55913485\n",
    "We accordingly decide the move direction.\n",
    "'''\n",
    "\n",
    "def do_normalization(path, path_out_, ID, model, \n",
    "                     std_sholder=0.323, std_neck=0.197, std_x=0.502, std_y=0.559):\n",
    "    \n",
    "    #extract keypoint\n",
    "    vec_array, fps, n_frames, f_H, f_W = obtain_key_vector(path, model)\n",
    "    \n",
    "    #calculate average neck end to nose dist\n",
    "    ave_neck = 0.\n",
    "    for i in range(len(vec_array)):\n",
    "        x1 = vec_array[i]['bodies']['candidate'][0][0]\n",
    "        y1 = vec_array[i]['bodies']['candidate'][0][1]\n",
    "        x2 = vec_array[i]['bodies']['candidate'][1][0]\n",
    "        y2 = vec_array[i]['bodies']['candidate'][1][1]\n",
    "        distance = compute_l2_distance([x1, y1], [x2, y2])\n",
    "        ave_neck += distance\n",
    "    ave_neck = ave_neck/len(vec_array)\n",
    "    \n",
    "    #calcuate average sholder dist\n",
    "    ave_sholder = 0.\n",
    "    for i in range(len(vec_array)):\n",
    "        x1 = vec_array[i]['bodies']['candidate'][2][0]\n",
    "        y1 = vec_array[i]['bodies']['candidate'][2][1]\n",
    "        x2 = vec_array[i]['bodies']['candidate'][5][0]\n",
    "        y2 = vec_array[i]['bodies']['candidate'][5][1]\n",
    "        distance = compute_l2_distance([x1, y1], [x2, y2])\n",
    "        ave_sholder += distance\n",
    "    ave_sholder = ave_sholder/len(vec_array)\n",
    "    \n",
    "    #obtain the resize rate\n",
    "    r_h = std_neck/ave_neck\n",
    "    r_w = std_sholder/ave_sholder\n",
    "    \n",
    "    #unlike resize rate, we only use the first frame to decide movement direction\n",
    "    mv_x = std_x - vec_array[0]['bodies']['candidate'][1][0]\n",
    "    mv_y = std_y - vec_array[0]['bodies']['candidate'][1][1]\n",
    "    \n",
    "    #resize mp and DW\n",
    "    vec_array_new = list()\n",
    "    \n",
    "    for i in range(len(vec_array)):\n",
    "        processed = process_keypoints(vec_array[i], \n",
    "                                      resize_height_rate=r_h, resize_width_rate=r_w,\n",
    "                                      move_x=mv_x, move_y=mv_y)\n",
    "        vec_array_new.append(processed)\n",
    "        \n",
    "\n",
    "    #save to file\n",
    "    Dict_ = defaultdict()\n",
    "    \n",
    "    Dict_['keypoint'] = vec_array_new\n",
    "\n",
    "    Dict_['info'] = {'video_file_location': path,\n",
    "                     'fps': fps, 'number_of_frames': n_frames, 'H': f_H, 'W': f_W}\n",
    "    \n",
    "    with open(path_out_ + str(ID) + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(Dict_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b99e9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_create_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove all contents inside the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "    else:\n",
    "        # Create the folder if it doesn't exist\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ee930c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_videos/8.mp4',\n",
       " 'input_videos/36.mp4',\n",
       " 'input_videos/468.mp4',\n",
       " 'input_videos/487.mp4']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_sort_videos(path_in):\n",
    "    # Convert to Path object\n",
    "    input_path = Path(path_in)\n",
    "    \n",
    "    # Get all files with .mp4 or .mov extension\n",
    "    video_files = list(input_path.glob('*.[mM][pP]4')) + list(input_path.glob('*.[mM][oO][vV]'))\n",
    "    \n",
    "    # Dictionary to check for duplicates\n",
    "    id_check = {}\n",
    "    \n",
    "    # List to store (id, path) pairs\n",
    "    valid_videos = []\n",
    "    \n",
    "    for video_path in video_files:\n",
    "        # Get filename without extension\n",
    "        name = video_path.stem\n",
    "        ext = video_path.suffix.lower()\n",
    "        \n",
    "        # Check file extension\n",
    "        if ext not in ['.mp4', '.mov']:\n",
    "            raise ValueError(f\"Invalid file format found: {video_path}\")\n",
    "        \n",
    "        # Check if filename is integer\n",
    "        try:\n",
    "            video_id = int(name)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Non-integer filename found: {name}\")\n",
    "        \n",
    "        # Check for duplicates\n",
    "        if video_id in id_check:\n",
    "            raise ValueError(f\"Duplicate video ID found: {video_id}\")\n",
    "        \n",
    "        id_check[video_id] = True\n",
    "        valid_videos.append((video_id, video_path))\n",
    "    \n",
    "    # Sort by ID\n",
    "    valid_videos.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Return only the paths in sorted order\n",
    "    return [str(path) for _, path in valid_videos]\n",
    "\n",
    "\n",
    "######################\n",
    "path_in = \"./input_videos/\"\n",
    "sorted_videos = load_and_sort_videos(path_in)\n",
    "sorted_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "301c0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#########the class############\n",
    "class KeyPointNormalization:\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        \n",
    "        self.path_in = \"./input_videos/\"\n",
    "        self.path_out = \"./results/\"\n",
    "        self.model = model\n",
    "        \n",
    "        self.sorted_videos = load_and_sort_videos(self.path_in)\n",
    "        clean_and_create_folder(self.path_out)\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(len(self.sorted_videos)):\n",
    "            do_normalization(self.sorted_videos[i], self.path_out, i, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "949bb192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/test_DWPose/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /Users/czhang/_Sorenson/_Projects/Sign_Language_Generation/code/kp_normalization_multi_video/ailab_DWPose/ControlNet-v1-1-nightly/annotator/dwpose/../ckpts/yolox_l.onnx failed:Load model /Users/czhang/_Sorenson/_Projects/Sign_Language_Generation/code/kp_normalization_multi_video/ailab_DWPose/ControlNet-v1-1-nightly/annotator/dwpose/../ckpts/yolox_l.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the model and other classes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m DW_model \u001b[38;5;241m=\u001b[39m \u001b[43mDWposeDetector_canlin_no_output_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m kp_normalizer \u001b[38;5;241m=\u001b[39m KeyPointNormalization(DW_model)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Run key point extraction\u001b[39;00m\n",
      "File \u001b[0;32m./ailab_DWPose/ControlNet-v1-1-nightly/annotator/dwpose/__init__.py:117\u001b[0m, in \u001b[0;36mDWposeDetector_canlin_no_output_img.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpose_estimation \u001b[38;5;241m=\u001b[39m \u001b[43mWholebody_canlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m./ailab_DWPose/ControlNet-v1-1-nightly/annotator/dwpose/wholebody.py:67\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test_DWPose/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:419\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test_DWPose/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:452\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    450\u001b[0m session_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01melse\u001b[39;00m C\u001b[38;5;241m.\u001b[39mget_default_session_options()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_path:\n\u001b[0;32m--> 452\u001b[0m     sess \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_config_from_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     sess \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mInferenceSession(session_options, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_bytes, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_config_from_model)\n",
      "\u001b[0;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from /Users/czhang/_Sorenson/_Projects/Sign_Language_Generation/code/kp_normalization_multi_video/ailab_DWPose/ControlNet-v1-1-nightly/annotator/dwpose/../ckpts/yolox_l.onnx failed:Load model /Users/czhang/_Sorenson/_Projects/Sign_Language_Generation/code/kp_normalization_multi_video/ailab_DWPose/ControlNet-v1-1-nightly/annotator/dwpose/../ckpts/yolox_l.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "# Initialize the model and other classes\n",
    "DW_model = DWposeDetector_canlin_no_output_img()\n",
    "kp_normalizer = KeyPointNormalization(DW_model)\n",
    "\n",
    "# Run key point extraction\n",
    "kp_normalizer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637c53e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Non-even integer filename found: 9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_13251/1096642348.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./results/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0msorted_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_even_pickles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_13251/1096642348.py\u001b[0m in \u001b[0;36mload_even_pickles\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# Check if it's even\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfile_id\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Non-even integer filename found: {file_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Non-even integer filename found: 9"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def load_even_pickles(folder_path):\n",
    "  # Convert to Path object\n",
    "  folder = Path(folder_path)\n",
    "  \n",
    "  # Get all pickle files\n",
    "  pickle_files = list(folder.glob('*.pickle'))\n",
    "  \n",
    "  # List to store (id, path) pairs\n",
    "  valid_pickles = []\n",
    "  id_check = {}\n",
    "  \n",
    "  for pickle_path in pickle_files:\n",
    "      # Get filename without extension\n",
    "      name = pickle_path.stem\n",
    "      \n",
    "      # Check if filename is integer\n",
    "      try:\n",
    "          file_id = int(name)\n",
    "      except ValueError:\n",
    "          raise ValueError(f\"Non-integer filename found: {name}\")\n",
    "          \n",
    "      # Check if it's even\n",
    "      if file_id % 2 != 0:\n",
    "          raise ValueError(f\"Non-even integer filename found: {file_id}\")\n",
    "          \n",
    "      # Check for duplicates\n",
    "      if file_id in id_check:\n",
    "          raise ValueError(f\"Duplicate ID found: {file_id}\")\n",
    "          \n",
    "      id_check[file_id] = True\n",
    "      valid_pickles.append((file_id, pickle_path))\n",
    "  \n",
    "  # Sort by ID\n",
    "  valid_pickles.sort(key=lambda x: x[0])\n",
    "  \n",
    "  # Return just the filenames (ID.pickle)\n",
    "  return [f\"{id}.pickle\" for id, _ in valid_pickles]\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"./results/\"\n",
    "sorted_filenames = load_even_pickles(folder_path)\n",
    "print(sorted_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69717a20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Non-integer filename found: normalized_keypoints",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_13251/3639922161.py\u001b[0m in \u001b[0;36mload_pickles\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m           \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'normalized_keypoints'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_13251/3639922161.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./results/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0msorted_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pickles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l9/fq_8_68563qggshjz7hrlslc0000gq/T/ipykernel_13251/3639922161.py\u001b[0m in \u001b[0;36mload_pickles\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Non-integer filename found: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Non-integer filename found: normalized_keypoints"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def load_pickles(folder_path):\n",
    "  # Convert to Path object\n",
    "  folder = Path(folder_path)\n",
    "  \n",
    "  # Get all pickle files\n",
    "  pickle_files = list(folder.glob('*.pickle'))\n",
    "  \n",
    "  # List to store (id, path) pairs\n",
    "  valid_pickles = []\n",
    "  id_check = {}\n",
    "  \n",
    "  for pickle_path in pickle_files:\n",
    "      # Get filename without extension\n",
    "      name = pickle_path.stem\n",
    "      \n",
    "      # Check if filename is integer\n",
    "      try:\n",
    "          file_id = int(name)\n",
    "      except ValueError:\n",
    "          raise ValueError(f\"Non-integer filename found: {name}\")\n",
    "          \n",
    "      # Check for duplicates\n",
    "      if file_id in id_check:\n",
    "          raise ValueError(f\"Duplicate ID found: {file_id}\")\n",
    "          \n",
    "      id_check[file_id] = True\n",
    "      valid_pickles.append((file_id, pickle_path))\n",
    "  \n",
    "  # Sort by ID\n",
    "  valid_pickles.sort(key=lambda x: x[0])\n",
    "  \n",
    "  # Return just the filenames (ID.pickle)\n",
    "  return [f\"{id}.pickle\" for id, _ in valid_pickles]\n",
    "\n",
    "# Example usage:\n",
    "folder_path = \"./results/\"\n",
    "sorted_filenames = load_pickles(folder_path)\n",
    "print(sorted_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26aca30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43447a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d12f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cfc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #instead, we only use the first frame of shoulder, which is likely the most steady front face location\n",
    "    x1 = vec_array[0]['bodies']['candidate'][2][0]\n",
    "    y1 = vec_array[0]['bodies']['candidate'][2][1]\n",
    "    x2 = vec_array[0]['bodies']['candidate'][5][0]\n",
    "    y2 = vec_array[0]['bodies']['candidate'][5][1]\n",
    "    fst_sholder = compute_l2_distance([x1, y1], [x2, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7eaa418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between [1, 0, 0] and [2, 0, 0] is: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_3d_distance(point1, point2):\n",
    "  # Convert inputs to numpy arrays for easier calculation\n",
    "  p1 = np.array(point1)\n",
    "  p2 = np.array(point2)\n",
    "  \n",
    "  # Calculate distance using numpy's built-in norm function\n",
    "  distance = np.linalg.norm(p2 - p1)\n",
    "  \n",
    "  return distance\n",
    "\n",
    "# Example usage\n",
    "point1 = [1, 0, 0]\n",
    "point2 = [2, 0, 0]\n",
    "\n",
    "distance = calculate_3d_distance(point1, point2)\n",
    "print(f\"The distance between {point1} and {point2} is: {distance:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37932876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bodies': {'candidate': array([[0.85, 0.4 ],\n",
      "       [0.6 , 0.4 ],\n",
      "       [1.15, 0.8 ],\n",
      "       [0.8 , 0.6 ],\n",
      "       [1.45, 1.2 ]]), 'subset': array([[0., 1., 2.]])}, 'hands': array([[[ 1.15,  1.4 ],\n",
      "        [ 1.45,  1.8 ]],\n",
      "\n",
      "       [[ 0.25,  0.2 ],\n",
      "        [-1.  , -1.  ]]]), 'faces': array([[[0.7 , 0.4 ],\n",
      "        [0.85, 0.6 ]]]), 'pose_mp': array([0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 ,\n",
      "       0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 0.6 ,\n",
      "       0.4 , 0.2 , 0.5 , 0.3 , 0.1 , 1.  , 0.6 , 0.2 , 0.5 , 0.3 , 0.1 ,\n",
      "       0.6 , 0.4 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.5 , 0.3 ,\n",
      "       0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85,\n",
      "       0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 ,\n",
      "       0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 ,\n",
      "       0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  ,\n",
      "       0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 ,\n",
      "       1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 ,\n",
      "       0.1 , 1.  , 0.6 , 0.2 , 0.85, 0.4 , 0.1 , 1.  , 0.6 , 0.2 ]), 'left_hand_mp': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'confidence_score_mp': 3.0}\n"
     ]
    }
   ],
   "source": [
    "def process_keypoints(keypoints_dict, resize_height_rate=1.0, resize_width_rate=1.0, move_x=0.0, move_y=0.0,\n",
    "                   pose_mp_mask=None, dwpose_body_mask=None):\n",
    "  \"\"\"\n",
    "  Resize and move keypoints in the dictionary while maintaining specific formats and rules.\n",
    "  \n",
    "  Args:\n",
    "      keypoints_dict: Dictionary containing different types of keypoints\n",
    "      resize_height_rate: float, rate to resize in height (y-direction)\n",
    "      resize_width_rate: float, rate to resize in width (x-direction)\n",
    "      move_x: float, displacement in x direction\n",
    "      move_y: float, displacement in y direction\n",
    "      pose_mp_mask: list or None, keypoint indices to keep unchanged in pose_mp \n",
    "                   (e.g., [11,12] means keeping keypoints 11,12 unchanged, \n",
    "                    which corresponds to dimensions [33:39] in the array)\n",
    "      dwpose_body_mask: list or None, keypoint indices to keep unchanged in DWpose body\n",
    "                       (e.g., [1,2,3] means keeping keypoints 1,2,3 unchanged)\n",
    "  \n",
    "  Returns:\n",
    "      Dictionary with processed keypoints\n",
    "  \"\"\"\n",
    "  result_dict = {}\n",
    "  \n",
    "  # Helper function to process 2D array of shape (..., 2)\n",
    "  def process_2d_points(points, mask_indices=None):\n",
    "      # Check for invalid points (x or y < -0.9)\n",
    "      invalid_mask = np.any(points < -0.9, axis=-1)\n",
    "      \n",
    "      # Process valid points\n",
    "      processed = points.copy()\n",
    "      \n",
    "      if mask_indices is not None:\n",
    "          # Create a boolean mask for points to change\n",
    "          change_mask = np.ones(points.shape[0], dtype=bool)\n",
    "          change_mask[mask_indices] = False\n",
    "          \n",
    "          # Only process non-masked points\n",
    "          processed[change_mask, 0] = points[change_mask, 0] * resize_width_rate + move_x\n",
    "          processed[change_mask, 1] = points[change_mask, 1] * resize_height_rate + move_y\n",
    "      else:\n",
    "          # Process all points\n",
    "          processed[..., 0] = points[..., 0] * resize_width_rate + move_x\n",
    "          processed[..., 1] = points[..., 1] * resize_height_rate + move_y\n",
    "      \n",
    "      # Reset invalid points to [-1, -1]\n",
    "      processed[invalid_mask] = [-1, -1]\n",
    "      return processed\n",
    "  \n",
    "  # Helper function to process 1D array with z values\n",
    "  def process_1d_points_with_z(points, mask_indices=None):\n",
    "      if np.all(points == 0):  # If all zeros, return as is\n",
    "          return points\n",
    "          \n",
    "      n_points = len(points) // 3\n",
    "      reshaped = points.reshape(n_points, 3)\n",
    "      processed = reshaped.copy()\n",
    "      \n",
    "      if mask_indices is not None:\n",
    "          # Create a boolean mask for points to change\n",
    "          change_mask = np.ones(n_points, dtype=bool)\n",
    "          change_mask[mask_indices] = False\n",
    "          \n",
    "          # Only process non-masked points\n",
    "          processed[change_mask, 0] = reshaped[change_mask, 0] * resize_width_rate + move_x\n",
    "          processed[change_mask, 1] = reshaped[change_mask, 1] * resize_height_rate + move_y\n",
    "      else:\n",
    "          # Process all points\n",
    "          processed[:, 0] = reshaped[:, 0] * resize_width_rate + move_x\n",
    "          processed[:, 1] = reshaped[:, 1] * resize_height_rate + move_y\n",
    "      \n",
    "      return processed.reshape(-1)\n",
    "  \n",
    "  # Process DWPose body keypoints\n",
    "  if 'bodies' in keypoints_dict:\n",
    "      result_dict['bodies'] = {\n",
    "          'candidate': process_2d_points(keypoints_dict['bodies']['candidate'], \n",
    "                                      mask_indices=dwpose_body_mask),\n",
    "          'subset': keypoints_dict['bodies']['subset'].copy()  # Keep subset unchanged\n",
    "      }\n",
    "  \n",
    "  # Process DWPose hands (process all points)\n",
    "  if 'hands' in keypoints_dict:\n",
    "      result_dict['hands'] = process_2d_points(keypoints_dict['hands'])\n",
    "  \n",
    "  # Process DWPose faces (unstack first dim)\n",
    "  if 'faces' in keypoints_dict:\n",
    "      faces = keypoints_dict['faces']\n",
    "      processed_faces = process_2d_points(faces[0])  # Process the unstacked array\n",
    "      result_dict['faces'] = processed_faces[np.newaxis, ...]  # Stack back\n",
    "  \n",
    "  # Process MediaPipe keypoints (all ending with _mp)\n",
    "  for key in keypoints_dict:\n",
    "      if key.endswith('_mp'):\n",
    "          if key == 'confidence_score_mp':\n",
    "              result_dict[key] = keypoints_dict[key]  # Keep confidence score unchanged\n",
    "          elif key == 'pose_mp':\n",
    "              # Convert pose_mp_mask to array indices if provided\n",
    "              array_mask = None\n",
    "              if pose_mp_mask is not None:\n",
    "                  array_mask = [i for point in pose_mp_mask for i in range(point, point+1)]\n",
    "              result_dict[key] = process_1d_points_with_z(keypoints_dict[key], \n",
    "                                                        mask_indices=array_mask)\n",
    "          else:\n",
    "              # Process all points for other MediaPipe keypoints\n",
    "              result_dict[key] = process_1d_points_with_z(keypoints_dict[key])\n",
    "  \n",
    "  return result_dict\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "  # Create a small example dictionary\n",
    "  example_dict = {\n",
    "      'bodies': {\n",
    "          'candidate': np.array([[0.5, 0.3], [0.6, 0.4], [0.7, 0.5], \n",
    "                               [0.8, 0.6], [0.9, 0.7]]),  # 5 points for demonstration\n",
    "          'subset': np.array([[0., 1., 2.]])\n",
    "      },\n",
    "      'hands': np.array([[[0.7, 0.8], [0.9, 1.0]], [[0.1, 0.2], [-1, -1]]]),\n",
    "      'faces': np.array([[[0.4, 0.3], [0.5, 0.4]]]),\n",
    "      'pose_mp': np.array([0.5, 0.3, 0.1, 0.6, 0.4, 0.2] * 20),  # Example array\n",
    "      'left_hand_mp': np.zeros(63),\n",
    "      'confidence_score_mp': 3.0\n",
    "  }\n",
    "  \n",
    "  # Process the keypoints with masking\n",
    "  processed = process_keypoints(\n",
    "      example_dict,\n",
    "      resize_height_rate=2.0,\n",
    "      resize_width_rate=1.5,\n",
    "      move_x=0.1,\n",
    "      move_y=-0.2,\n",
    "      pose_mp_mask=[7, 8, 10, 11, 14],  # Keep keypoints 11,12 unchanged\n",
    "      dwpose_body_mask=[1, 3]  # Keep keypoints 1,2,3 unchanged\n",
    "  )\n",
    "\n",
    "  print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b10b12cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.3, 0.1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['pose_mp'][3*14:3*14+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af26c7a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(1, 14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708c31f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b858a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31743641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa46c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb79a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0faeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91b0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71ffb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d9b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3d8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81222702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aee3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e231e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383dc7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906314d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0dd895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f281d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb335e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbad16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ffc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2f455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eec3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6b3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94006639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd329835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb484046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ecbf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4daab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
